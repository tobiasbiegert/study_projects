{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import xarray as xr\n",
    "from properscoring import crps_gaussian\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from weatherbench2.metrics import _spatial_average\n",
    "from weatherbench2.visualization import set_wb2_style\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_wb2_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_wb2_style()\n",
    "\n",
    "plt.rcParams['mathtext.fontset'] = 'stix'\n",
    "plt.rcParams['font.family'] = 'STIXGeneral'\n",
    "plt.rcParams.update({'font.size': 28})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_spatial_avg(values, forecast_global):\n",
    "    \"\"\"\n",
    "    Calculates the spatial average of a numpy.ndarray based on the global forecast coordinates.\n",
    "\n",
    "    Parameters:\n",
    "        - values (numpy.ndarray): Array of values to be averaged.\n",
    "        - forecast_global (xarray.Dataset): Global forecast dataset containing longitude and latitude coordinates.\n",
    "\n",
    "    Returns:\n",
    "        float: Spatial average of the input values.\n",
    "    \"\"\"\n",
    "    # Create a DataArray using the provided values and coordinates from forecast_global\n",
    "    da = xr.DataArray(\n",
    "            values,\n",
    "            dims=['longitude', 'latitude'],\n",
    "            coords={'longitude': forecast_global.longitude, 'latitude': forecast_global.latitude}\n",
    "        )\n",
    "    \n",
    "    # Calculate the spatial average using the weatherbench2 function _spatial_average\n",
    "    result = _spatial_average(da).values.item()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_spatial_avg_metrics(df):\n",
    "    \n",
    "    df_mi = df.set_index(['latitude', 'longitude', 'lead_time'])\n",
    "    columns_to_include = df_mi.columns\n",
    "    \n",
    "    # Create xarray Dataset for all specified columns\n",
    "    ds_emos = xr.Dataset({\n",
    "        column: (['lead_time', 'latitude', 'longitude'], df_mi[column].values.reshape((-1, len(df_mi.index.levels[0]), len(df_mi.index.levels[1]))))\n",
    "        for column in columns_to_include\n",
    "    }, coords={ \n",
    "        'latitude': df_mi.index.levels[0], \n",
    "        'longitude': df_mi.index.levels[1],\n",
    "        'lead_time': df_mi.index.levels[2]\n",
    "    })\n",
    "    \n",
    "    # Calculate spatial average for each metric\n",
    "    spatial_avg_metrics = xr.Dataset()\n",
    "    spatial_avg_metrics[df_mi.columns[1:]] = _spatial_average(ds_emos[df_mi.columns[1:]])\n",
    "    \n",
    "    return ds_emos, spatial_avg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_std(ds, spatial=False, s=None):\n",
    "    if s is not None:\n",
    "        # extract values\n",
    "        emos_param_c_values = ds['emos_params_x'].str[2].values.tolist()\n",
    "        emos_param_c_values = np.squeeze(np.array(emos_param_c_values), axis=-1)\n",
    "        emos_param_d_values = ds['emos_params_x'].str[3].values.tolist()\n",
    "        emos_param_d_values = np.squeeze(np.array(emos_param_d_values), axis=-1)\n",
    "        # squeeze last axis\n",
    "        local_std = np.exp(emos_param_c_values + emos_param_d_values * np.tile(np.log(s).values[:, np.newaxis, np.newaxis], (1, 32, 64)))\n",
    "    else:\n",
    "        # extract values\n",
    "        emos_param_values = ds['emos_params_x'].str[2].values.tolist()\n",
    "        # squeeze last axis and transform to sigma\n",
    "        local_std = np.exp(np.squeeze(np.array(emos_param_values), axis=-1))\n",
    "    \n",
    "    if spatial:\n",
    "        # Transpose dimensions and calculate spatial average\n",
    "        local_std_transposed = np.transpose(local_std, axes=(0, 2, 1))\n",
    "        local_std_avg = pd.Series(index=ds.lead_time, dtype='float64')\n",
    "        for i in range(len(local_std_avg)):\n",
    "            local_std_avg.iloc[i] = np_spatial_avg(local_std_transposed[i,:,:], ds)\n",
    "    else:\n",
    "        local_std_avg = pd.Series(np.mean(local_std, axis=(1, 2)), index=ds.lead_time)\n",
    "        \n",
    "    return local_std_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emos_crps(params, ens_mean, obs, ens_sd=None, forecast_global=None):\n",
    "    \"\"\"\n",
    "    Calculates the Continuous Ranked Probability Score (CRPS) for (ensemble) forecast using EMOS.\n",
    "\n",
    "    Parameters:\n",
    "        - params (list): List of parameters for EMOS link functions.\n",
    "        - ens_mean (numpy.ndarray): Forecast ensemble mean values.\n",
    "        - obs (numpy.ndarray): Observed values.\n",
    "        - ens_sd (numpy.ndarray, optional): Forecast ensemble standard deviation values.\n",
    "        - forecast_global (xarray.Dataset, optional): Global forecast dataset containing longitude and latitude coordinates.\n",
    "\n",
    "    Returns:\n",
    "        float: CRPS value for the given ensemble forecast and observations.\n",
    "    \"\"\"\n",
    "    # Extract parameters\n",
    "    a, b, c, *rest = params\n",
    "    d = rest[0] if rest else None\n",
    "    \n",
    "    # Calculate location\n",
    "    loc_emos = a + b * ens_mean\n",
    "    \n",
    "    # Calculate standard deviation  \n",
    "    if ens_sd is None:\n",
    "        scale_emos = np.exp(c + d * np.log(ens_mean)) if rest else np.exp(c)\n",
    "    else:\n",
    "        scale_emos = np.exp(c + d * np.log(ens_sd))\n",
    "    \n",
    "    # Calculate CRPS\n",
    "    if forecast_global is None:\n",
    "        # only one gridpoint\n",
    "        crps = np.mean(crps_gaussian(obs, loc_emos, scale_emos))\n",
    "        return crps\n",
    "    else:\n",
    "        # all grid points\n",
    "        crps_values = crps_gaussian(obs, loc_emos, scale_emos).mean(axis=0)\n",
    "        return np_spatial_avg(crps_values, forecast_global)\n",
    "\n",
    "def emos_crps_grad(params, ens_mean, obs, ens_sd=None, forecast_global=None):\n",
    "    \"\"\"\n",
    "    Calculates the gradient of the Continuous Ranked Probability Score (CRPS) for ensemble forecast using EMOS.\n",
    "\n",
    "    Parameters:\n",
    "        - params (list): List of parameters for EMOS link functions.\n",
    "        - ens_mean (numpy.ndarray): Forecast ensemble mean values.\n",
    "        - obs (numpy.ndarray): Observed values.\n",
    "        - ens_sd (numpy.ndarray, optional): Forecast ensemble standard deviation values.\n",
    "        - forecast_global (xarray.Dataset, optional): Global forecast dataset containing longitude and latitude coordinates.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Gradient of CRPS with respect to parameters.\n",
    "    \"\"\"\n",
    "    # Extract parameters\n",
    "    a, b, c, *rest = params\n",
    "    d = rest[0] if rest else None\n",
    "    \n",
    "    # Calculate location\n",
    "    loc_emos = a + b * ens_mean\n",
    "    \n",
    "    # Calculate standard deviation  \n",
    "    if ens_sd is None:\n",
    "        scale_emos = np.exp(c + d * np.log(ens_mean)) if rest else np.exp(c)\n",
    "    else:\n",
    "        scale_emos = np.exp(c + d * np.log(ens_sd))\n",
    "    \n",
    "    # Calculate CRPS gradient\n",
    "    _, grad_crps = crps_gaussian(obs, loc_emos, scale_emos, grad=True)\n",
    "    \n",
    "    # Extract components\n",
    "    dmu, dsd = grad_crps[0], grad_crps[1]\n",
    "    \n",
    "    if forecast_global is None:\n",
    "        # Apply chain rule for the location link function\n",
    "        da = np.mean(dmu)\n",
    "        db = np.mean(dmu * ens_mean)\n",
    "        # Apply chain rule for the scale link function\n",
    "        if not rest and ens_sd is None: \n",
    "            dc = np.mean(dsd * np.exp(c))\n",
    "            return da, db, dc\n",
    "        elif rest and ens_sd is None:\n",
    "            dc = np.mean(dsd * np.exp(c + d * np.log(ens_mean)))\n",
    "            dd = np.mean(dsd * np.exp(c + d * np.log(ens_mean)) * np.log(ens_mean))\n",
    "            return da, db, dc, dd\n",
    "        elif rest and ens_sd is not None:\n",
    "            dc = np.mean(dsd * np.exp(c + d * np.log(ens_sd)))\n",
    "            dd = np.mean(dsd * np.exp(c + d * np.log(ens_sd)) * np.log(ens_sd))\n",
    "            return da, db, dc, dd\n",
    "        else:\n",
    "            raise ValueError('Not the right number of parameters for an ensemble forecast!')\n",
    "        \n",
    "    else:\n",
    "        # Apply chain rule and calculate spatial average\n",
    "        da_values = dmu.mean(axis=0)\n",
    "        da = np_spatial_avg(da_values, forecast_global)\n",
    "        \n",
    "        db_values = (dmu * ens_mean).mean(axis=0)\n",
    "        db = np_spatial_avg(db_values, forecast_global)\n",
    "        \n",
    "        if not rest and ens_sd is None: \n",
    "            dc_values = (dsd * np.exp(c)).mean(axis=0)\n",
    "            dc = np_spatial_avg(dc_values, forecast_global)\n",
    "            return da, db, dc\n",
    "        elif rest and ens_sd is None:\n",
    "            dc_values = (dsd * np.exp(c + d * np.log(ens_mean))).mean(axis=0)\n",
    "            dc = np_spatial_avg(dc_values, forecast_global)\n",
    "                \n",
    "            dd_values = (dsd * np.exp(c + d * np.log(ens_mean)) * np.log(ens_mean)).mean(axis=0)\n",
    "            dd = np_spatial_avg(dd_values, forecast_global)\n",
    "            return da, db, dc, dd\n",
    "        elif rest and ens_sd is not None:\n",
    "            dc_values = (dsd * np.exp(c + d * np.log(ens_sd))).mean(axis=0)\n",
    "            dc = np_spatial_avg(dc_values, forecast_global)\n",
    "                \n",
    "            dd_values = (dsd * np.exp(c + d * np.log(ens_sd)) * np.log(ens_sd)).mean(axis=0)\n",
    "            dd = np_spatial_avg(dd_values, forecast_global)\n",
    "            return da, db, dc, dd\n",
    "        else:\n",
    "            raise ValueError('Not the right number of parameters for an ensemble forecast!')\n",
    "\n",
    "# Function for EMOS estimation\n",
    "def emos_est(ens_mean, obs, par_start, ens_sd=None, forecast_global=None):\n",
    "    \"\"\"\n",
    "    Estimates EMOS parameters using optimization based on CRPS.\n",
    "\n",
    "    Parameters:\n",
    "        - ens_mean (numpy.ndarray): Forecast ensemble mean values.\n",
    "        - obs (numpy.ndarray): Observed values.\n",
    "        - par_start (list): Initial values for EMOS parameters.\n",
    "        - ens_sd (numpy.ndarray, optional): Forecast ensemble standard deviation values.\n",
    "        - forecast_global (xarray.Dataset, optional): Global forecast dataset containing longitude and latitude coordinates.\n",
    "\n",
    "    Returns:\n",
    "        scipy.optimize.OptimizeResult: Result of the optimization, including the estimated parameters.\n",
    "    \"\"\"\n",
    "    # Optimization using the BFGS method\n",
    "    result = minimize(emos_crps, par_start, args=(ens_mean, obs, ens_sd, forecast_global), jac=emos_crps_grad)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T850"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pangu Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PANGU done in 189.48 seconds\n",
      "Obs done in 5.44 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Load PANGU data\n",
    "pangu = xr.open_zarr('gs://weatherbench2/datasets/pangu/2018-2022_0012_64x32_equiangular_conservative.zarr')['temperature'].sel(level=850)\n",
    "pangu = pangu.compute()\n",
    "pangu_done_time = time.time() - start_time\n",
    "print('PANGU done in {:.2f} seconds'.format(pangu_done_time))\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "# Load ERA5 data\n",
    "obs = xr.open_zarr('gs://weatherbench2/datasets/era5/1959-2023_01_10-6h-64x32_equiangular_conservative.zarr')['temperature'].sel(level=850, time=slice(pangu.time[0], pangu.time[-1]))\n",
    "obs = obs.compute()\n",
    "\n",
    "obs_done_time = time.time() - start_time\n",
    "print('Obs done in {:.2f} seconds'.format(obs_done_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c&d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 81920/81920 [04:53<00:00, 278.91it/s]\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "def process_location(lat, lon, lead_time):\n",
    "    try:\n",
    "        pangu_subset = pangu.sel(latitude=lat, longitude=lon, prediction_timedelta=lead_time)\n",
    "\n",
    "        # Split PANGU data into training and test sets\n",
    "        pangu_train = xr.concat([pangu_subset.sel(time=slice(None, '2019-12-31')),\n",
    "                                 pangu_subset.sel(time=slice('2021-01-01', obs.time[-1] - pd.to_timedelta(lead_time)))], dim='time')\n",
    "        pangu_test = pangu_subset.sel(time=slice('2020-01-01', '2020-12-31'))\n",
    "\n",
    "        # Load ERA5 data\n",
    "        obs_train = obs.sel(latitude=lat, longitude=lon, time=pangu_train.time + lead_time)\n",
    "        obs_test = obs.sel(latitude=lat, longitude=lon, time=pangu_test.time + lead_time)\n",
    "\n",
    "        # Extract values from datasets\n",
    "        pangu_train_values = pangu_train.values\n",
    "        pangu_test_values = pangu_test.values\n",
    "        obs_train_values = obs_train.values\n",
    "        obs_test_values = obs_test.values\n",
    "\n",
    "        # Train EMOS model\n",
    "        emos_params = emos_est(pangu_train_values, obs_train_values, par_start=[0, 0, 0, 0])\n",
    "\n",
    "        # Calculate expected value of EMOS ensemble\n",
    "        emos_mu = emos_params.x[0] + emos_params.x[1] * pangu_test_values\n",
    "\n",
    "        # Calculate CRPS, MAE, and MSE for EMOS using the expected value\n",
    "        crps_emos = emos_crps(emos_params.x, pangu_test_values, obs_test_values)\n",
    "        mae_emos = np.mean(np.abs(emos_mu - obs_test_values))\n",
    "        mse_emos = np.mean((emos_mu - obs_test_values)**2)\n",
    "\n",
    "        # Calculate MAE and MSE for deterministic forecast\n",
    "        mae_det = np.mean(np.abs(pangu_test_values - obs_test_values))\n",
    "        mse_det = np.mean((pangu_test_values - obs_test_values)**2)\n",
    "\n",
    "        return {\n",
    "            'latitude': lat,\n",
    "            'longitude': lon,\n",
    "            'lead_time': lead_time,\n",
    "            'emos_params_x': emos_params.x.tolist(),\n",
    "            'crps_emos': crps_emos,\n",
    "            'mae_emos': mae_emos,\n",
    "            'mse_emos': mse_emos,\n",
    "            'mae_det': mae_det,\n",
    "            'mse_det': mse_det\n",
    "        }\n",
    "    except Exception as e:\n",
    "        # Log the error\n",
    "        print(f\"An error occurred for lat={lat}, lon={lon}, lead_time={lead_time}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Automatically determine the number of workers based on CPU cores\n",
    "num_workers = int(multiprocessing.cpu_count() * 0.5)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor, tqdm(total=len(pangu.prediction_timedelta.values) * len(pangu.latitude.values) * len(pangu.longitude.values)) as pbar:\n",
    "    futures = []\n",
    "    for lead_time in pangu.prediction_timedelta.values:\n",
    "        for lat in pangu.latitude.values:\n",
    "            for lon in pangu.longitude.values:\n",
    "                future = executor.submit(process_location, lat, lon, lead_time)\n",
    "                futures.append(future)\n",
    "\n",
    "    # Wait for all futures to complete\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        result_list.append(future.result())\n",
    "        pbar.update(1)\n",
    "\n",
    "executor.shutdown(wait=True)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "result_df = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.sort_values(by=['lead_time', 'latitude', 'longitude']).to_pickle('EMOS/pangu_2020_c_d.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### just c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 81920/81920 [04:02<00:00, 337.33it/s]\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "def process_location(lat, lon, lead_time):\n",
    "    try:\n",
    "        pangu_subset = pangu.sel(latitude=lat, longitude=lon, prediction_timedelta=lead_time)\n",
    "\n",
    "        # Split PANGU data into training and test sets\n",
    "        pangu_train = xr.concat([pangu_subset.sel(time=slice(None, '2019-12-31')),\n",
    "                                 pangu_subset.sel(time=slice('2021-01-01', obs.time[-1] - pd.to_timedelta(lead_time)))], dim='time')\n",
    "        pangu_test = pangu_subset.sel(time=slice('2020-01-01', '2020-12-31'))\n",
    "\n",
    "        # Load ERA5 data\n",
    "        obs_train = obs.sel(latitude=lat, longitude=lon, time=pangu_train.time + lead_time)\n",
    "        obs_test = obs.sel(latitude=lat, longitude=lon, time=pangu_test.time + lead_time)\n",
    "\n",
    "        # Extract values from datasets\n",
    "        pangu_train_values = pangu_train.values\n",
    "        pangu_test_values = pangu_test.values\n",
    "        obs_train_values = obs_train.values\n",
    "        obs_test_values = obs_test.values\n",
    "\n",
    "        # Train EMOS model\n",
    "        emos_params = emos_est(pangu_train_values, obs_train_values, par_start=[0, 0, 0])\n",
    "\n",
    "        # Calculate expected value of EMOS ensemble\n",
    "        emos_mu = emos_params.x[0] + emos_params.x[1] * pangu_test_values\n",
    "\n",
    "        # Calculate CRPS, MAE, and MSE for EMOS using the expected value\n",
    "        crps_emos = emos_crps(emos_params.x, pangu_test_values, obs_test_values)\n",
    "        mae_emos = np.mean(np.abs(emos_mu - obs_test_values))\n",
    "        mse_emos = np.mean((emos_mu - obs_test_values)**2)\n",
    "\n",
    "        # Calculate MAE and MSE for deterministic forecast\n",
    "        mae_det = np.mean(np.abs(pangu_test_values - obs_test_values))\n",
    "        mse_det = np.mean((pangu_test_values - obs_test_values)**2)\n",
    "\n",
    "        return {\n",
    "            'latitude': lat,\n",
    "            'longitude': lon,\n",
    "            'lead_time': lead_time,\n",
    "            'emos_params_x': emos_params.x.tolist(),\n",
    "            'crps_emos': crps_emos,\n",
    "            'mae_emos': mae_emos,\n",
    "            'mse_emos': mse_emos,\n",
    "            'mae_det': mae_det,\n",
    "            'mse_det': mse_det\n",
    "        }\n",
    "    except Exception as e:\n",
    "        # Log the error\n",
    "        print(f\"An error occurred for lat={lat}, lon={lon}, lead_time={lead_time}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Automatically determine the number of workers based on CPU cores\n",
    "num_workers = int(multiprocessing.cpu_count() * 0.5)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor, tqdm(total=len(pangu.prediction_timedelta.values) * len(pangu.latitude.values) * len(pangu.longitude.values)) as pbar:\n",
    "    futures = []\n",
    "    for lead_time in pangu.prediction_timedelta.values:\n",
    "        for lat in pangu.latitude.values:\n",
    "            for lon in pangu.longitude.values:\n",
    "                future = executor.submit(process_location, lat, lon, lead_time)\n",
    "                futures.append(future)\n",
    "\n",
    "    # Wait for all futures to complete\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        result_list.append(future.result())\n",
    "        pbar.update(1)\n",
    "\n",
    "executor.shutdown(wait=True)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "result_df = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.sort_values(by=['lead_time', 'latitude', 'longitude']).to_pickle('EMOS/pangu_2020_c.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pangu Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [03:23<00:00,  5.10s/it]\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "def process_lead_time(lead_time):\n",
    "    pangu_subset = pangu.sel(prediction_timedelta=lead_time)\n",
    "\n",
    "    # Split pangu data into training and test sets\n",
    "    pangu_train = xr.concat([pangu_subset.sel(time=slice(None, '2019-12-31')),\n",
    "                             pangu_subset.sel(time=slice('2021-01-01', obs.time[-1] - pd.to_timedelta(lead_time)))], dim='time')\n",
    "    pangu_test = pangu_subset.sel(time=slice('2020-01-01', '2020-12-31'))\n",
    "\n",
    "    # Load ERA5 data\n",
    "    obs_train = obs.sel(time=pangu_train.time + lead_time)\n",
    "    obs_test = obs.sel(time=pangu_test.time + lead_time)\n",
    "\n",
    "    # Extract values from datasets\n",
    "    pangu_train_values = pangu_train.values\n",
    "    pangu_test_values = pangu_test.values\n",
    "    obs_train_values = obs_train.values\n",
    "    obs_test_values = obs_test.values\n",
    "\n",
    "    # Train EMOS model\n",
    "    emos_params = emos_est(ens_mean=pangu_train_values, obs=obs_train_values, par_start=[0, 0, 0], forecast_global=pangu_train)\n",
    "\n",
    "    # Calculate expected value of EMOS ensemble\n",
    "    emos_mu = emos_params.x[0] + emos_params.x[1] * pangu_test_values\n",
    "\n",
    "    # Calculate CRPS, MAE, and MSE for EMOS using the expected value\n",
    "    crps_emos = emos_crps(params=emos_params.x, ens_mean=pangu_test_values, obs=obs_test_values, forecast_global=pangu_test)\n",
    "    mae_emos = np_spatial_avg(np.abs(emos_mu - obs_test_values).mean(axis=0),pangu_test)\n",
    "    mse_emos = np_spatial_avg(((emos_mu - obs_test_values)**2).mean(axis=0),pangu_test)\n",
    "\n",
    "    # Calculate MAE and MSE for deterministic forecast (replace this line with your deterministic forecast calculation)\n",
    "    mae_det = np_spatial_avg(np.abs(pangu_test_values - obs_test_values).mean(axis=0),pangu_test)\n",
    "    mse_det = np_spatial_avg(((pangu_test_values - obs_test_values)**2).mean(axis=0), pangu_test)\n",
    "\n",
    "    return {\n",
    "        'lead_time': lead_time,\n",
    "        'emos_params_x': emos_params.x.tolist(),\n",
    "        'crps_emos': crps_emos,\n",
    "        'mae_emos': mae_emos,\n",
    "        'mse_emos': mse_emos,\n",
    "        'mae_det': mae_det,\n",
    "        'mse_det': mse_det\n",
    "    }\n",
    "\n",
    "# Automatically determine the number of workers based on CPU cores\n",
    "num_workers = int(multiprocessing.cpu_count() * 0.5)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor, tqdm(total=len(pangu.prediction_timedelta.values)) as pbar:\n",
    "    futures = []\n",
    "    for lead_time in pangu.prediction_timedelta.values:\n",
    "        future = executor.submit(process_lead_time, lead_time)\n",
    "        futures.append(future)\n",
    "\n",
    "    # Wait for all futures to complete\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        result_list.append(future.result())\n",
    "        pbar.update(1)\n",
    "\n",
    "executor.shutdown(wait=True)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "result_df = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.sort_values(by='lead_time').to_pickle('EMOS/pangu_2020_global_c.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphCast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graphcast done in 209.82 seconds\n",
      "Obs done in 3.80 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Load GraphCast data\n",
    "graphcast = xr.concat([xr.open_zarr('gs://weatherbench2/datasets/graphcast/2018/date_range_2017-11-16_2019-02-01_12_hours-64x32_equiangular_conservative.zarr'), xr.open_zarr('gs://weatherbench2/datasets/graphcast/2020/date_range_2019-11-16_2021-02-01_12_hours-64x32_equiangular_conservative.zarr')],dim='time')['temperature'].sel(level=850)\n",
    "graphcast = graphcast.compute()\n",
    "graphcast_done_time = time.time() - start_time\n",
    "print('graphcast done in {:.2f} seconds'.format(graphcast_done_time))\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "# Load ERA5 data\n",
    "obs = xr.open_zarr('gs://weatherbench2/datasets/era5/1959-2023_01_10-6h-64x32_equiangular_conservative.zarr')['temperature'].sel(level=850, time=slice(graphcast.time[0], graphcast.time[-1]))\n",
    "obs = obs.compute()\n",
    "\n",
    "obs_done_time = time.time() - start_time\n",
    "print('Obs done in {:.2f} seconds'.format(obs_done_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [01:12<00:00,  1.82s/it]\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "def process_lead_time(lead_time):\n",
    "    graphcast_subset = graphcast.sel(prediction_timedelta=lead_time)\n",
    "\n",
    "    # Split graphcast data into training and test sets\n",
    "    graphcast_train = xr.concat([graphcast_subset.sel(time=slice(None, '2019-12-31')),\n",
    "                             graphcast_subset.sel(time=slice('2021-01-01', obs.time[-1] - pd.to_timedelta(lead_time)))], dim='time')\n",
    "    graphcast_test = graphcast_subset.sel(time=slice('2020-01-01', '2020-12-31'))\n",
    "\n",
    "    # Load ERA5 data\n",
    "    obs_train = obs.sel(time=graphcast_train.time + lead_time)\n",
    "    obs_test = obs.sel(time=graphcast_test.time + lead_time)\n",
    "\n",
    "    # Extract values from datasets\n",
    "    graphcast_train_values = graphcast_train.values\n",
    "    graphcast_test_values = graphcast_test.values\n",
    "    obs_train_values = obs_train.values\n",
    "    obs_test_values = obs_test.values\n",
    "\n",
    "    # Train EMOS model\n",
    "    emos_params = emos_est(ens_mean=graphcast_train_values, obs=obs_train_values, par_start=[0, 0, 0], forecast_global=graphcast_train)\n",
    "\n",
    "    # Calculate expected value of EMOS ensemble\n",
    "    emos_mu = emos_params.x[0] + emos_params.x[1] * graphcast_test_values\n",
    "\n",
    "    # Calculate CRPS, MAE, and MSE for EMOS using the expected value\n",
    "    crps_emos = emos_crps(params=emos_params.x, ens_mean=graphcast_test_values, obs=obs_test_values, forecast_global=graphcast_test)\n",
    "    mae_emos = np_spatial_avg(np.abs(emos_mu - obs_test_values).mean(axis=0),graphcast_test)\n",
    "    mse_emos = np_spatial_avg(((emos_mu - obs_test_values)**2).mean(axis=0),graphcast_test)\n",
    "\n",
    "    # Calculate MAE and MSE for deterministic forecast (replace this line with your deterministic forecast calculation)\n",
    "    mae_det = np_spatial_avg(np.abs(graphcast_test_values - obs_test_values).mean(axis=0),graphcast_test)\n",
    "    mse_det = np_spatial_avg(((graphcast_test_values - obs_test_values)**2).mean(axis=0), graphcast_test)\n",
    "\n",
    "    return {\n",
    "        'lead_time': lead_time,\n",
    "        'emos_params_x': emos_params.x.tolist(),\n",
    "        'crps_emos': crps_emos,\n",
    "        'mae_emos': mae_emos,\n",
    "        'mse_emos': mse_emos,\n",
    "        'mae_det': mae_det,\n",
    "        'mse_det': mse_det\n",
    "    }\n",
    "\n",
    "# Automatically determine the number of workers based on CPU cores\n",
    "num_workers = int(multiprocessing.cpu_count() * 0.5)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor, tqdm(total=len(graphcast.prediction_timedelta.values)) as pbar:\n",
    "    futures = []\n",
    "    for lead_time in graphcast.prediction_timedelta.values:\n",
    "        future = executor.submit(process_lead_time, lead_time)\n",
    "        futures.append(future)\n",
    "\n",
    "    # Wait for all futures to complete\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        result_list.append(future.result())\n",
    "        pbar.update(1)\n",
    "\n",
    "executor.shutdown(wait=True)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "result_df = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.sort_values(by='lead_time').reset_index(drop=True).to_pickle('EMOS/graphcast_2020_global_c.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 81920/81920 [03:08<00:00, 435.44it/s]\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "def process_location(lat, lon, lead_time):\n",
    "    graphcast_subset = graphcast.sel(latitude=lat, longitude=lon, prediction_timedelta=lead_time)\n",
    "\n",
    "    # Split graphcast data into training and test sets\n",
    "    graphcast_train = xr.concat([graphcast_subset.sel(time=slice(None, '2019-12-31')),\n",
    "                             graphcast_subset.sel(time=slice('2021-01-01', obs.time[-1] - pd.to_timedelta(lead_time)))], dim='time')\n",
    "    graphcast_test = graphcast_subset.sel(time=slice('2020-01-01', '2020-12-31'))\n",
    "\n",
    "    # Load ERA5 data\n",
    "    obs_train = obs.sel(latitude=lat, longitude=lon, time=graphcast_train.time + lead_time)\n",
    "    obs_test = obs.sel(latitude=lat, longitude=lon, time=graphcast_test.time + lead_time)\n",
    "\n",
    "    # Extract values from datasets\n",
    "    graphcast_train_values = graphcast_train.values\n",
    "    graphcast_test_values = graphcast_test.values\n",
    "    obs_train_values = obs_train.values\n",
    "    obs_test_values = obs_test.values\n",
    "\n",
    "    # Train EMOS model\n",
    "    emos_params = emos_est(graphcast_train_values, obs_train_values, par_start=[0, 0, 0])\n",
    "\n",
    "    # Calculate expected value of EMOS ensemble\n",
    "    emos_mu = emos_params.x[0] + emos_params.x[1] * graphcast_test_values\n",
    "\n",
    "    # Calculate CRPS, MAE, and MSE for EMOS using the expected value\n",
    "    crps_emos = emos_crps(emos_params.x, graphcast_test_values, obs_test_values)\n",
    "    mae_emos = np.mean(np.abs(emos_mu - obs_test_values))\n",
    "    mse_emos = np.mean((emos_mu - obs_test_values)**2)\n",
    "\n",
    "    # Calculate MAE and MSE for deterministic forecast (replace this line with your deterministic forecast calculation)\n",
    "    mae_det = np.mean(np.abs(graphcast_test_values - obs_test_values))\n",
    "    mse_det = np.mean((graphcast_test_values - obs_test_values)**2)\n",
    "\n",
    "    return {\n",
    "        'latitude': lat,\n",
    "        'longitude': lon,\n",
    "        'lead_time': lead_time,\n",
    "        'emos_params_x': emos_params.x.tolist(),\n",
    "        'crps_emos': crps_emos,\n",
    "        'mae_emos': mae_emos,\n",
    "        'mse_emos': mse_emos,\n",
    "        'mae_det': mae_det,\n",
    "        'mse_det': mse_det\n",
    "    }\n",
    "\n",
    "# Automatically determine the number of workers based on CPU cores\n",
    "num_workers = int(multiprocessing.cpu_count() * 0.5)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor, tqdm(total=len(graphcast.prediction_timedelta.values) * len(graphcast.latitude.values) * len(graphcast.longitude.values)) as pbar:\n",
    "    futures = []\n",
    "    for lead_time in graphcast.prediction_timedelta.values:\n",
    "        for lat in graphcast.latitude.values:\n",
    "            for lon in graphcast.longitude.values:\n",
    "                future = executor.submit(process_location, lat, lon, lead_time)\n",
    "                futures.append(future)\n",
    "\n",
    "    # Wait for all futures to complete\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        result_list.append(future.result())\n",
    "        pbar.update(1)\n",
    "\n",
    "executor.shutdown(wait=True)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "result_df = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.sort_values(by=['lead_time', 'latitude', 'longitude']).to_pickle('EMOS/graphcast_2020_c.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## HRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HRES done in 922.06 seconds\n",
      "Obs done in 8.66 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Load HRES data\n",
    "hres = xr.open_zarr('gs://weatherbench2/datasets/hres/2016-2022-0012-64x32_equiangular_conservative.zarr')['temperature'].sel(level=850)\n",
    "hres = hres.compute()\n",
    "hres_done_time = time.time() - start_time\n",
    "print('HRES done in {:.2f} seconds'.format(hres_done_time))\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "# Load Analysis data\n",
    "obs = xr.open_zarr('gs://weatherbench2/datasets/hres_t0/2016-2022-6h-64x32_equiangular_conservative.zarr')['temperature'].sel(level=850, time=slice('2016-01-01', '2022-12-31'))\n",
    "obs = obs.compute()\n",
    "\n",
    "obs_done_time = time.time() - start_time\n",
    "print('Obs done in {:.2f} seconds'.format(obs_done_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [05:32<00:00,  8.11s/it]\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "def process_lead_time(lead_time):\n",
    "    hres_subset = hres.sel(prediction_timedelta=lead_time)\n",
    "\n",
    "    # Split hres data into training and test sets\n",
    "    hres_train = xr.concat([hres_subset.sel(time=slice('2016-01-01', '2019-12-31')),\n",
    "                             hres_subset.sel(time=slice('2021-01-01', obs.time[-2] - pd.to_timedelta(lead_time)))], dim='time')\n",
    "    hres_test = hres_subset.sel(time=slice('2020-01-01', '2020-12-31'))\n",
    "\n",
    "    # Load ERA5 data\n",
    "    obs_train = obs.sel(time=hres_train.time + lead_time)\n",
    "    obs_test = obs.sel(time=hres_test.time + lead_time)\n",
    "\n",
    "    # Extract values from datasets\n",
    "    hres_train_values = hres_train.values\n",
    "    hres_test_values = hres_test.values\n",
    "    obs_train_values = obs_train.values\n",
    "    obs_test_values = obs_test.values\n",
    "\n",
    "    # Train EMOS model\n",
    "    emos_params = emos_est(ens_mean=hres_train_values, obs=obs_train_values, par_start=[0, 0, 0], forecast_global=hres_train)\n",
    "\n",
    "    # Calculate expected value of EMOS ensemble\n",
    "    emos_mu = emos_params.x[0] + emos_params.x[1] * hres_test_values\n",
    "\n",
    "    # Calculate CRPS, MAE, and MSE for EMOS using the expected value\n",
    "    crps_emos = emos_crps(params=emos_params.x, ens_mean=hres_test_values, obs=obs_test_values, forecast_global=hres_test)\n",
    "    mae_emos = np_spatial_avg(np.abs(emos_mu - obs_test_values).mean(axis=0),hres_test)\n",
    "    mse_emos = np_spatial_avg(((emos_mu - obs_test_values)**2).mean(axis=0),hres_test)\n",
    "\n",
    "    # Calculate MAE and MSE for deterministic forecast (replace this line with your deterministic forecast calculation)\n",
    "    mae_det = np_spatial_avg(np.abs(hres_test_values - obs_test_values).mean(axis=0),hres_test)\n",
    "    mse_det = np_spatial_avg(((hres_test_values - obs_test_values)**2).mean(axis=0), hres_test)\n",
    "\n",
    "    return {\n",
    "        'lead_time': lead_time,\n",
    "        'emos_params_x': emos_params.x.tolist(),\n",
    "        'crps_emos': crps_emos,\n",
    "        'mae_emos': mae_emos,\n",
    "        'mse_emos': mse_emos,\n",
    "        'mae_det': mae_det,\n",
    "        'mse_det': mse_det\n",
    "    }\n",
    "\n",
    "# Automatically determine the number of workers based on CPU cores\n",
    "num_workers = int(multiprocessing.cpu_count() * 0.5)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor, tqdm(total=len(hres.prediction_timedelta.values)) as pbar:\n",
    "    futures = []\n",
    "    for lead_time in hres.prediction_timedelta.values:\n",
    "        future = executor.submit(process_lead_time, lead_time)\n",
    "        futures.append(future)\n",
    "\n",
    "    # Wait for all futures to complete\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        result_list.append(future.result())\n",
    "        pbar.update(1)\n",
    "\n",
    "executor.shutdown(wait=True)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "result_df = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.sort_values(by='lead_time').to_pickle('EMOS/hres_2020_global_c.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 83968/83968 [04:55<00:00, 284.45it/s]\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "def process_location(lat, lon, lead_time):\n",
    "    hres_subset = hres.sel(latitude=lat, longitude=lon, prediction_timedelta=lead_time)\n",
    "\n",
    "    # Split hres data into training and test sets\n",
    "    hres_train = xr.concat([hres_subset.sel(time=slice('2016-01-01', '2019-12-31')),\n",
    "                             hres_subset.sel(time=slice('2021-01-01', obs.time[-2] - pd.to_timedelta(lead_time)))], dim='time')\n",
    "    hres_test = hres_subset.sel(time=slice('2020-01-01', '2020-12-31'))\n",
    "\n",
    "    # Load ERA5 data\n",
    "    obs_train = obs.sel(latitude=lat, longitude=lon, time=hres_train.time + lead_time)\n",
    "    obs_test = obs.sel(latitude=lat, longitude=lon, time=hres_test.time + lead_time)\n",
    "\n",
    "    # Extract values from datasets\n",
    "    hres_train_values = hres_train.values\n",
    "    hres_test_values = hres_test.values\n",
    "    obs_train_values = obs_train.values\n",
    "    obs_test_values = obs_test.values\n",
    "\n",
    "    # Train EMOS model\n",
    "    emos_params = emos_est(hres_train_values, obs_train_values, par_start=[0, 0, 0])\n",
    "\n",
    "    # Calculate expected value of EMOS ensemble\n",
    "    emos_mu = emos_params.x[0] + emos_params.x[1] * hres_test_values\n",
    "\n",
    "    # Calculate CRPS, MAE, and MSE for EMOS using the expected value\n",
    "    crps_emos = emos_crps(emos_params.x, hres_test_values, obs_test_values)\n",
    "    mae_emos = np.mean(np.abs(emos_mu - obs_test_values))\n",
    "    mse_emos = np.mean((emos_mu - obs_test_values)**2)\n",
    "\n",
    "    # Calculate MAE and MSE for deterministic forecast (replace this line with your deterministic forecast calculation)\n",
    "    mae_det = np.mean(np.abs(hres_test_values - obs_test_values))\n",
    "    mse_det = np.mean((hres_test_values - obs_test_values)**2)\n",
    "\n",
    "    return {\n",
    "        'latitude': lat,\n",
    "        'longitude': lon,\n",
    "        'lead_time': lead_time,\n",
    "        'emos_params_x': emos_params.x.tolist(),\n",
    "        'crps_emos': crps_emos,\n",
    "        'mae_emos': mae_emos,\n",
    "        'mse_emos': mse_emos,\n",
    "        'mae_det': mae_det,\n",
    "        'mse_det': mse_det\n",
    "    }\n",
    "\n",
    "# Automatically determine the number of workers based on CPU cores\n",
    "num_workers = int(multiprocessing.cpu_count() * 0.5)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor, tqdm(total=len(hres.prediction_timedelta.values) * len(hres.latitude.values) * len(hres.longitude.values)) as pbar:\n",
    "    futures = []\n",
    "    for lead_time in hres.prediction_timedelta.values:\n",
    "        for lat in hres.latitude.values:\n",
    "            for lon in hres.longitude.values:\n",
    "                future = executor.submit(process_location, lat, lon, lead_time)\n",
    "                futures.append(future)\n",
    "\n",
    "    # Wait for all futures to complete\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        result_list.append(future.result())\n",
    "        pbar.update(1)\n",
    "\n",
    "executor.shutdown(wait=True)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "result_df = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.sort_values(by=['lead_time', 'latitude', 'longitude']).to_pickle('EMOS/hres_2020_c.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IFS ENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IFS ENS done in 1.38 seconds\n",
      "Obs done in 5.22 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Load IFS ENS data\n",
    "ens = xr.open_zarr('gs://weatherbench2/datasets/ens/2018-2022-64x32_equiangular_conservative.zarr')['temperature'].sel(level=850)\n",
    "#ens = ens.compute()\n",
    "ens_done_time = time.time() - start_time\n",
    "print('IFS ENS done in {:.2f} seconds'.format(ens_done_time))\n",
    "\n",
    "start_time = time.time()\n",
    "# Load Analysis data\n",
    "obs = xr.open_zarr('gs://weatherbench2/datasets/hres_t0/2016-2022-6h-64x32_equiangular_conservative.zarr')['temperature'].sel(level=850, time=slice('2018-01-01', '2022-12-31'))\n",
    "obs = obs.compute()\n",
    "\n",
    "obs_done_time = time.time() - start_time\n",
    "print('Obs done in {:.2f} seconds'.format(obs_done_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lead times: 100%|██████████████████| 61/61 [1:15:39<00:00, 74.42s/it]\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "for lead_time in tqdm(ens.prediction_timedelta.values, desc=\"Processing lead times\"):\n",
    "    \n",
    "    ens_subset = ens.sel(prediction_timedelta=lead_time)\n",
    "    ens_subset = ens_subset.compute()\n",
    "\n",
    "    # Split ens data into training and test sets\n",
    "    ens_train = xr.concat([ens_subset.sel(time=slice('2018-01-01', '2019-12-31')),\n",
    "                             ens_subset.sel(time=slice('2021-01-01', obs.time[-2] - pd.to_timedelta(lead_time)))], dim='time')\n",
    "    ens_test = ens_subset.sel(time=slice('2020-01-01', '2020-12-31'))\n",
    "\n",
    "    # Load ERA5 data\n",
    "    obs_train = obs.sel(time=ens_train.time + lead_time)\n",
    "    obs_test = obs.sel(time=ens_test.time + lead_time)\n",
    "\n",
    "    # Extract values from datasets\n",
    "    ens_train_values = ens_train.values\n",
    "    ens_test_values = ens_test.values\n",
    "    obs_train_values = obs_train.values\n",
    "    obs_test_values = obs_test.values\n",
    "\n",
    "    # Train EMOS model \n",
    "    emos_params = emos_est(ens_mean=ens_train_values.mean(axis=1), obs=obs_train_values, par_start=[0, 0, 0, 0], ens_sd=ens_train_values.std(axis=1), forecast_global=ens_train)\n",
    "\n",
    "    # Calculate expected value of EMOS ensemble\n",
    "    ens_test_values_mean = ens_test_values.mean(axis=1)\n",
    "    emos_mu = emos_params.x[0] + emos_params.x[1] * ens_test_values_mean\n",
    "\n",
    "    # Calculate CRPS, MAE, and MSE for EMOS using the expected value\n",
    "    crps_emos = emos_crps(params=emos_params.x, ens_mean=ens_test_values_mean, obs=obs_test_values, ens_sd=ens_test_values.std(axis=1), forecast_global=ens_test)\n",
    "    mae_emos = np_spatial_avg(np.abs(emos_mu - obs_test_values).mean(axis=0),ens_test)\n",
    "    mse_emos = np_spatial_avg(((emos_mu - obs_test_values)**2).mean(axis=0),ens_test)\n",
    "\n",
    "    # Calculate MAE and MSE for deterministic forecast (replace this line with your deterministic forecast calculation)\n",
    "    ens_mean_mae = np_spatial_avg(np.abs(ens_test_values_mean - obs_test_values).mean(axis=0),ens_test)\n",
    "    ens_mean_mse = np_spatial_avg(((ens_test_values_mean - obs_test_values)**2).mean(axis=0), ens_test)\n",
    "\n",
    "    # Append results to the list\n",
    "    result_list.append({\n",
    "        'lead_time': lead_time,\n",
    "        'emos_params_x': emos_params.x.tolist(),\n",
    "        'crps_emos': crps_emos,\n",
    "        'mae_emos': mae_emos,\n",
    "        'mse_emos': mse_emos,\n",
    "        'ens_mean_mae': ens_mean_mae,\n",
    "        'ens_mean_mse': ens_mean_mse\n",
    "    })\n",
    "    \n",
    "# Convert the list of dictionaries to a DataFrame and save it for each iteration\n",
    "result_df = pd.DataFrame(result_list)\n",
    "result_df['ens_crps'] = xr.open_dataset('Results_CLS/64x32/probabilistic/ens_vs_analysis_2020_temperature_probabilistic.nc')['temperature'].sel(metric='crps').values\n",
    "result_df.to_pickle('EMOS/ens_2020_global.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "\n",
    "with tqdm(total=len(ens.prediction_timedelta.values) * len(ens.latitude.values) * len(ens.longitude.values)) as pbar:\n",
    "    for lead_time in ens.prediction_timedelta.values:\n",
    "        ens_sub = ens.sel(prediction_timedelta=lead_time)\n",
    "        ens_sub = ens_sub.compute()\n",
    "        for lat in ens.latitude.values:\n",
    "            for lon in ens.longitude.values:\n",
    "\n",
    "                ens_subset = ens_sub.sel(latitude=lat, longitude=lon)#, prediction_timedelta=lead_time)\n",
    "\n",
    "                # Split ens data into training and test sets\n",
    "                ens_train = xr.concat([ens_subset.sel(time=slice('2016-01-01', '2019-12-31')),\n",
    "                                         ens_subset.sel(time=slice('2021-01-01', obs.time[-2] - pd.to_timedelta(lead_time)))], dim='time')\n",
    "                ens_test = ens_subset.sel(time=slice('2020-01-01', '2020-12-31'))\n",
    "\n",
    "                # Load ERA5 data\n",
    "                obs_train = obs.sel(latitude=lat, longitude=lon, time=ens_train.time + lead_time)\n",
    "                obs_test = obs.sel(latitude=lat, longitude=lon, time=ens_test.time + lead_time)\n",
    "\n",
    "                # Extract values from datasets\n",
    "                ens_train_values = ens_train.values\n",
    "                ens_test_values = ens_test.values\n",
    "                obs_train_values = obs_train.values\n",
    "                obs_test_values = obs_test.values\n",
    "\n",
    "                # Train EMOS model\n",
    "                emos_params = emos_est(ens_mean=ens_train_values.mean(axis=1), obs=obs_train_values, par_start=[0, 0, 0, 0], ens_sd=ens_train_values.std(axis=1))\n",
    "\n",
    "                # Calculate expected value of EMOS ensemble\n",
    "                ens_test_values_mean = ens_test_values.mean(axis=1)\n",
    "                emos_mu = emos_params.x[0] + emos_params.x[1] * ens_test_values_mean\n",
    "\n",
    "                # Calculate CRPS, MAE, and MSE for EMOS using the expected value\n",
    "                crps_emos = emos_crps(params=emos_params.x, ens_mean=ens_test_values_mean, obs=obs_test_values, ens_sd=ens_test_values.std(axis=1))\n",
    "                mae_emos = np.mean(np.abs(emos_mu - obs_test_values))\n",
    "                mse_emos = np.mean((emos_mu - obs_test_values)**2)\n",
    "\n",
    "                # Calculate MAE and MSE for deterministic forecast (replace this line with your deterministic forecast calculation)\n",
    "                ens_mean_mae = np.mean(np.abs(ens_test_values_mean - obs_test_values))\n",
    "                ens_mean_mse = np.mean((ens_test_values_mean - obs_test_values)**2)\n",
    "\n",
    "                # Append results to the list\n",
    "                result_list.append({\n",
    "                    'latitude': lat,\n",
    "                    'longitude': lon,\n",
    "                    'lead_time': lead_time,\n",
    "                    'emos_params_x': emos_params.x.tolist(),\n",
    "                    'crps_emos': crps_emos,\n",
    "                    'mae_emos': mae_emos,\n",
    "                    'mse_emos': mse_emos,\n",
    "                    'ens_mean_mae': ens_mean_mae,\n",
    "                    'ens_mean_mse': ens_mean_mse\n",
    "                })\n",
    "                \n",
    "                pbar.update(1)\n",
    "    \n",
    "# Convert the list of dictionaries to a DataFrame and save it for each iteration\n",
    "result_df = pd.DataFrame(result_list)\n",
    "#result_df['ens_crps'] = xr.open_dataset('Results_CLS/64x32/probabilistic/ens_vs_analysis_2020_temperature_probabilistic.nc')['temperature'].sel(metric='crps').values\n",
    "result_df.to_pickle('EMOS/ens_2020.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# T2M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pangu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PANGU done in 199.19 seconds\n",
      "Obs done in 2.97 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Load PANGU data\n",
    "pangu = xr.open_zarr('gs://weatherbench2/datasets/pangu/2018-2022_0012_64x32_equiangular_conservative.zarr')['2m_temperature']\n",
    "pangu = pangu.compute()\n",
    "pangu_done_time = time.time() - start_time\n",
    "print('PANGU done in {:.2f} seconds'.format(pangu_done_time))\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "# Load ERA5 data\n",
    "obs = xr.open_zarr('gs://weatherbench2/datasets/era5/1959-2023_01_10-6h-64x32_equiangular_conservative.zarr')['2m_temperature'].sel(time=slice(pangu.time[0], pangu.time[-1]))\n",
    "obs = obs.compute()\n",
    "\n",
    "obs_done_time = time.time() - start_time\n",
    "print('Obs done in {:.2f} seconds'.format(obs_done_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 81920/81920 [04:15<00:00, 320.18it/s]\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "def process_location(lat, lon, lead_time):\n",
    "    try:\n",
    "        pangu_subset = pangu.sel(latitude=lat, longitude=lon, prediction_timedelta=lead_time)\n",
    "\n",
    "        # Split PANGU data into training and test sets\n",
    "        pangu_train = xr.concat([pangu_subset.sel(time=slice(None, '2019-12-31')),\n",
    "                                 pangu_subset.sel(time=slice('2021-01-01', obs.time[-1] - pd.to_timedelta(lead_time)))], dim='time')\n",
    "        pangu_test = pangu_subset.sel(time=slice('2020-01-01', '2020-12-31'))\n",
    "\n",
    "        # Load ERA5 data\n",
    "        obs_train = obs.sel(latitude=lat, longitude=lon, time=pangu_train.time + lead_time)\n",
    "        obs_test = obs.sel(latitude=lat, longitude=lon, time=pangu_test.time + lead_time)\n",
    "\n",
    "        # Extract values from datasets\n",
    "        pangu_train_values = pangu_train.values\n",
    "        pangu_test_values = pangu_test.values\n",
    "        obs_train_values = obs_train.values\n",
    "        obs_test_values = obs_test.values\n",
    "\n",
    "        # Train EMOS model\n",
    "        emos_params = emos_est(pangu_train_values, obs_train_values, par_start=[0, 0, 0])\n",
    "\n",
    "        # Calculate expected value of EMOS ensemble\n",
    "        emos_mu = emos_params.x[0] + emos_params.x[1] * pangu_test_values\n",
    "\n",
    "        # Calculate CRPS, MAE, and MSE for EMOS using the expected value\n",
    "        crps_emos = emos_crps(emos_params.x, pangu_test_values, obs_test_values)\n",
    "        mae_emos = np.mean(np.abs(emos_mu - obs_test_values))\n",
    "        mse_emos = np.mean((emos_mu - obs_test_values)**2)\n",
    "\n",
    "        # Calculate MAE and MSE for deterministic forecast\n",
    "        mae_det = np.mean(np.abs(pangu_test_values - obs_test_values))\n",
    "        mse_det = np.mean((pangu_test_values - obs_test_values)**2)\n",
    "\n",
    "        return {\n",
    "            'latitude': lat,\n",
    "            'longitude': lon,\n",
    "            'lead_time': lead_time,\n",
    "            'emos_params_x': emos_params.x.tolist(),\n",
    "            'crps_emos': crps_emos,\n",
    "            'mae_emos': mae_emos,\n",
    "            'mse_emos': mse_emos,\n",
    "            'mae_det': mae_det,\n",
    "            'mse_det': mse_det\n",
    "        }\n",
    "    except Exception as e:\n",
    "        # Log the error\n",
    "        print(f\"An error occurred for lat={lat}, lon={lon}, lead_time={lead_time}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Automatically determine the number of workers based on CPU cores\n",
    "num_workers = int(multiprocessing.cpu_count() * 0.5)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor, tqdm(total=len(pangu.prediction_timedelta.values) * len(pangu.latitude.values) * len(pangu.longitude.values)) as pbar:\n",
    "    futures = []\n",
    "    for lead_time in pangu.prediction_timedelta.values:\n",
    "        for lat in pangu.latitude.values:\n",
    "            for lon in pangu.longitude.values:\n",
    "                future = executor.submit(process_location, lat, lon, lead_time)\n",
    "                futures.append(future)\n",
    "\n",
    "    # Wait for all futures to complete\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        result_list.append(future.result())\n",
    "        pbar.update(1)\n",
    "\n",
    "executor.shutdown(wait=True)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "result_df = pd.DataFrame(result_list).sort_values(by=['lead_time', 'latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.sort_values(by=['lead_time', 'latitude', 'longitude']).reset_index(drop=True).to_pickle('EMOS/T2M/pangu_2020_local.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [04:31<00:00,  6.78s/it]\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "def process_lead_time(lead_time):\n",
    "    pangu_subset = pangu.sel(prediction_timedelta=lead_time)\n",
    "\n",
    "    # Split pangu data into training and test sets\n",
    "    pangu_train = xr.concat([pangu_subset.sel(time=slice(None, '2019-12-31')),\n",
    "                             pangu_subset.sel(time=slice('2021-01-01', obs.time[-1] - pd.to_timedelta(lead_time)))], dim='time')\n",
    "    pangu_test = pangu_subset.sel(time=slice('2020-01-01', '2020-12-31'))\n",
    "\n",
    "    # Load ERA5 data\n",
    "    obs_train = obs.sel(time=pangu_train.time + lead_time)\n",
    "    obs_test = obs.sel(time=pangu_test.time + lead_time)\n",
    "\n",
    "    # Extract values from datasets\n",
    "    pangu_train_values = pangu_train.values\n",
    "    pangu_test_values = pangu_test.values\n",
    "    obs_train_values = obs_train.values\n",
    "    obs_test_values = obs_test.values\n",
    "\n",
    "    # Train EMOS model\n",
    "    emos_params = emos_est(ens_mean=pangu_train_values, obs=obs_train_values, par_start=[0, 0, 0], forecast_global=pangu_train)\n",
    "\n",
    "    # Calculate expected value of EMOS ensemble\n",
    "    emos_mu = emos_params.x[0] + emos_params.x[1] * pangu_test_values\n",
    "\n",
    "    # Calculate CRPS, MAE, and MSE for EMOS using the expected value\n",
    "    crps_emos = emos_crps(params=emos_params.x, ens_mean=pangu_test_values, obs=obs_test_values, forecast_global=pangu_test)\n",
    "    mae_emos = np_spatial_avg(np.abs(emos_mu - obs_test_values).mean(axis=0),pangu_test)\n",
    "    mse_emos = np_spatial_avg(((emos_mu - obs_test_values)**2).mean(axis=0),pangu_test)\n",
    "\n",
    "    # Calculate MAE and MSE for deterministic forecast (replace this line with your deterministic forecast calculation)\n",
    "    mae_det = np_spatial_avg(np.abs(pangu_test_values - obs_test_values).mean(axis=0),pangu_test)\n",
    "    mse_det = np_spatial_avg(((pangu_test_values - obs_test_values)**2).mean(axis=0), pangu_test)\n",
    "\n",
    "    return {\n",
    "        'lead_time': lead_time,\n",
    "        'emos_params_x': emos_params.x.tolist(),\n",
    "        'crps_emos': crps_emos,\n",
    "        'mae_emos': mae_emos,\n",
    "        'mse_emos': mse_emos,\n",
    "        'mae_det': mae_det,\n",
    "        'mse_det': mse_det\n",
    "    }\n",
    "\n",
    "# Automatically determine the number of workers based on CPU cores\n",
    "num_workers = int(multiprocessing.cpu_count() * 0.5)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor, tqdm(total=len(pangu.prediction_timedelta.values)) as pbar:\n",
    "    futures = []\n",
    "    for lead_time in pangu.prediction_timedelta.values:\n",
    "        future = executor.submit(process_lead_time, lead_time)\n",
    "        futures.append(future)\n",
    "\n",
    "    # Wait for all futures to complete\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        result_list.append(future.result())\n",
    "        pbar.update(1)\n",
    "\n",
    "executor.shutdown(wait=True)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "result_df = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.sort_values(by='lead_time').reset_index(drop=True).to_pickle('EMOS/T2M/pangu_2020_global.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphCast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graphcast done in 62.03 seconds\n",
      "Obs done in 1.11 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Load GraphCast data\n",
    "graphcast = xr.concat([xr.open_zarr('gs://weatherbench2/datasets/graphcast/2018/date_range_2017-11-16_2019-02-01_12_hours-64x32_equiangular_conservative.zarr'), xr.open_zarr('gs://weatherbench2/datasets/graphcast/2020/date_range_2019-11-16_2021-02-01_12_hours-64x32_equiangular_conservative.zarr')],dim='time')['2m_temperature']\n",
    "graphcast = graphcast.compute()\n",
    "graphcast_done_time = time.time() - start_time\n",
    "print('graphcast done in {:.2f} seconds'.format(graphcast_done_time))\n",
    "\n",
    "start_time = time.time()\n",
    "# Load ERA5 data\n",
    "obs = xr.open_zarr('gs://weatherbench2/datasets/era5/1959-2023_01_10-6h-64x32_equiangular_conservative.zarr')['2m_temperature'].sel(time=slice(graphcast.time[0], graphcast.time[-1]))\n",
    "obs = obs.compute()\n",
    "\n",
    "obs_done_time = time.time() - start_time\n",
    "print('Obs done in {:.2f} seconds'.format(obs_done_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 81920/81920 [04:04<00:00, 334.92it/s]\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "def process_location(lat, lon, lead_time):\n",
    "    try:\n",
    "        graphcast_subset = graphcast.sel(latitude=lat, longitude=lon, prediction_timedelta=lead_time)\n",
    "\n",
    "        # Split graphcast data into training and test sets\n",
    "        graphcast_train = xr.concat([graphcast_subset.sel(time=slice(None, '2019-12-31')),\n",
    "                                 graphcast_subset.sel(time=slice('2021-01-01', obs.time[-1] - pd.to_timedelta(lead_time)))], dim='time')\n",
    "        graphcast_test = graphcast_subset.sel(time=slice('2020-01-01', '2020-12-31'))\n",
    "\n",
    "        # Load ERA5 data\n",
    "        obs_train = obs.sel(latitude=lat, longitude=lon, time=graphcast_train.time + lead_time)\n",
    "        obs_test = obs.sel(latitude=lat, longitude=lon, time=graphcast_test.time + lead_time)\n",
    "\n",
    "        # Extract values from datasets\n",
    "        graphcast_train_values = graphcast_train.values\n",
    "        graphcast_test_values = graphcast_test.values\n",
    "        obs_train_values = obs_train.values\n",
    "        obs_test_values = obs_test.values\n",
    "\n",
    "        # Train EMOS model\n",
    "        emos_params = emos_est(graphcast_train_values, obs_train_values, par_start=[0, 0, 0])\n",
    "\n",
    "        # Calculate expected value of EMOS ensemble\n",
    "        emos_mu = emos_params.x[0] + emos_params.x[1] * graphcast_test_values\n",
    "\n",
    "        # Calculate CRPS, MAE, and MSE for EMOS using the expected value\n",
    "        crps_emos = emos_crps(emos_params.x, graphcast_test_values, obs_test_values)\n",
    "        mae_emos = np.mean(np.abs(emos_mu - obs_test_values))\n",
    "        mse_emos = np.mean((emos_mu - obs_test_values)**2)\n",
    "\n",
    "        # Calculate MAE and MSE for deterministic forecast (replace this line with your deterministic forecast calculation)\n",
    "        mae_det = np.mean(np.abs(graphcast_test_values - obs_test_values))\n",
    "        mse_det = np.mean((graphcast_test_values - obs_test_values)**2)\n",
    "\n",
    "        return {\n",
    "            'latitude': lat,\n",
    "            'longitude': lon,\n",
    "            'lead_time': lead_time,\n",
    "            'emos_params_x': emos_params.x.tolist(),\n",
    "            'crps_emos': crps_emos,\n",
    "            'mae_emos': mae_emos,\n",
    "            'mse_emos': mse_emos,\n",
    "            'mae_det': mae_det,\n",
    "            'mse_det': mse_det\n",
    "        }\n",
    "    except Exception as e:\n",
    "        # Log the error\n",
    "        print(f\"An error occurred for lat={lat}, lon={lon}, lead_time={lead_time}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Automatically determine the number of workers based on CPU cores\n",
    "num_workers = int(multiprocessing.cpu_count() * 0.4)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor, tqdm(total=len(graphcast.prediction_timedelta.values) * len(graphcast.latitude.values) * len(graphcast.longitude.values)) as pbar:\n",
    "    futures = []\n",
    "    for lead_time in graphcast.prediction_timedelta.values:\n",
    "        for lat in graphcast.latitude.values:\n",
    "            for lon in graphcast.longitude.values:\n",
    "                future = executor.submit(process_location, lat, lon, lead_time)\n",
    "                futures.append(future)\n",
    "\n",
    "    # Wait for all futures to complete\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        result_list.append(future.result())\n",
    "        pbar.update(1)\n",
    "\n",
    "executor.shutdown(wait=True)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "result_df = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.sort_values(by=['lead_time', 'latitude', 'longitude']).reset_index(drop=True).to_pickle('EMOS/T2M/graphcast_2020_local.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [01:25<00:00,  2.13s/it]\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "def process_lead_time(lead_time):\n",
    "    graphcast_subset = graphcast.sel(prediction_timedelta=lead_time)\n",
    "\n",
    "    # Split graphcast data into training and test sets\n",
    "    graphcast_train = xr.concat([graphcast_subset.sel(time=slice(None, '2019-12-31')),\n",
    "                             graphcast_subset.sel(time=slice('2021-01-01', obs.time[-1] - pd.to_timedelta(lead_time)))], dim='time')\n",
    "    graphcast_test = graphcast_subset.sel(time=slice('2020-01-01', '2020-12-31'))\n",
    "\n",
    "    # Load ERA5 data\n",
    "    obs_train = obs.sel(time=graphcast_train.time + lead_time)\n",
    "    obs_test = obs.sel(time=graphcast_test.time + lead_time)\n",
    "\n",
    "    # Extract values from datasets\n",
    "    graphcast_train_values = graphcast_train.values\n",
    "    graphcast_test_values = graphcast_test.values\n",
    "    obs_train_values = obs_train.values\n",
    "    obs_test_values = obs_test.values\n",
    "\n",
    "    # Train EMOS model\n",
    "    emos_params = emos_est(ens_mean=graphcast_train_values, obs=obs_train_values, par_start=[0, 0, 0], forecast_global=graphcast_train)\n",
    "\n",
    "    # Calculate expected value of EMOS ensemble\n",
    "    emos_mu = emos_params.x[0] + emos_params.x[1] * graphcast_test_values\n",
    "\n",
    "    # Calculate CRPS, MAE, and MSE for EMOS using the expected value\n",
    "    crps_emos = emos_crps(params=emos_params.x, ens_mean=graphcast_test_values, obs=obs_test_values, forecast_global=graphcast_test)\n",
    "    mae_emos = np_spatial_avg(np.abs(emos_mu - obs_test_values).mean(axis=0),graphcast_test)\n",
    "    mse_emos = np_spatial_avg(((emos_mu - obs_test_values)**2).mean(axis=0),graphcast_test)\n",
    "\n",
    "    # Calculate MAE and MSE for deterministic forecast (replace this line with your deterministic forecast calculation)\n",
    "    mae_det = np_spatial_avg(np.abs(graphcast_test_values - obs_test_values).mean(axis=0),graphcast_test)\n",
    "    mse_det = np_spatial_avg(((graphcast_test_values - obs_test_values)**2).mean(axis=0), graphcast_test)\n",
    "\n",
    "    return {\n",
    "        'lead_time': lead_time,\n",
    "        'emos_params_x': emos_params.x.tolist(),\n",
    "        'crps_emos': crps_emos,\n",
    "        'mae_emos': mae_emos,\n",
    "        'mse_emos': mse_emos,\n",
    "        'mae_det': mae_det,\n",
    "        'mse_det': mse_det\n",
    "    }\n",
    "\n",
    "# Automatically determine the number of workers based on CPU cores\n",
    "num_workers = int(multiprocessing.cpu_count() * 0.5)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor, tqdm(total=len(graphcast.prediction_timedelta.values)) as pbar:\n",
    "    futures = []\n",
    "    for lead_time in graphcast.prediction_timedelta.values:\n",
    "        future = executor.submit(process_lead_time, lead_time)\n",
    "        futures.append(future)\n",
    "\n",
    "    # Wait for all futures to complete\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        result_list.append(future.result())\n",
    "        pbar.update(1)\n",
    "\n",
    "executor.shutdown(wait=True)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "result_df = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.sort_values(by='lead_time').reset_index(drop=True).to_pickle('EMOS/T2M/graphcast_2020_global.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs done in 2.18 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Load HRES data\n",
    "hres = xr.open_zarr('gs://weatherbench2/datasets/hres/2016-2022-0012-64x32_equiangular_conservative.zarr')['2m_temperature']\n",
    "hres = hres.compute()\n",
    "hres_done_time = time.time() - start_time\n",
    "print('HRES done in {:.2f} seconds'.format(hres_done_time))\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "# Load Analysis data\n",
    "obs = xr.open_zarr('gs://weatherbench2/datasets/hres_t0/2016-2022-6h-64x32_equiangular_conservative.zarr')['2m_temperature'].sel(time=slice(hres.time[0], hres.time[-1]))\n",
    "obs = obs.compute()\n",
    "\n",
    "obs_done_time = time.time() - start_time\n",
    "print('Obs done in {:.2f} seconds'.format(obs_done_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 83968/83968 [04:57<00:00, 281.96it/s]\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "def process_location(lat, lon, lead_time):\n",
    "    hres_subset = hres.sel(latitude=lat, longitude=lon, prediction_timedelta=lead_time)\n",
    "\n",
    "    # Split hres data into training and test sets\n",
    "    hres_train = xr.concat([hres_subset.sel(time=slice(None, '2019-12-31')),\n",
    "                             hres_subset.sel(time=slice('2021-01-01', obs.time[-1] - pd.to_timedelta(lead_time)))], dim='time')\n",
    "    hres_test = hres_subset.sel(time=slice('2020-01-01', '2020-12-31'))\n",
    "\n",
    "    # Load ERA5 data\n",
    "    obs_train = obs.sel(latitude=lat, longitude=lon, time=hres_train.time + lead_time)\n",
    "    obs_test = obs.sel(latitude=lat, longitude=lon, time=hres_test.time + lead_time)\n",
    "\n",
    "    # Extract values from datasets\n",
    "    hres_train_values = hres_train.values\n",
    "    hres_test_values = hres_test.values\n",
    "    obs_train_values = obs_train.values\n",
    "    obs_test_values = obs_test.values\n",
    "\n",
    "    # Train EMOS model\n",
    "    emos_params = emos_est(hres_train_values, obs_train_values, par_start=[0, 0, 0])\n",
    "\n",
    "    # Calculate expected value of EMOS ensemble\n",
    "    emos_mu = emos_params.x[0] + emos_params.x[1] * hres_test_values\n",
    "\n",
    "    # Calculate CRPS, MAE, and MSE for EMOS using the expected value\n",
    "    crps_emos = emos_crps(emos_params.x, hres_test_values, obs_test_values)\n",
    "    mae_emos = np.mean(np.abs(emos_mu - obs_test_values))\n",
    "    mse_emos = np.mean((emos_mu - obs_test_values)**2)\n",
    "\n",
    "    # Calculate MAE and MSE for deterministic forecast (replace this line with your deterministic forecast calculation)\n",
    "    mae_det = np.mean(np.abs(hres_test_values - obs_test_values))\n",
    "    mse_det = np.mean((hres_test_values - obs_test_values)**2)\n",
    "\n",
    "    return {\n",
    "        'latitude': lat,\n",
    "        'longitude': lon,\n",
    "        'lead_time': lead_time,\n",
    "        'emos_params_x': emos_params.x.tolist(),\n",
    "        'crps_emos': crps_emos,\n",
    "        'mae_emos': mae_emos,\n",
    "        'mse_emos': mse_emos,\n",
    "        'mae_det': mae_det,\n",
    "        'mse_det': mse_det\n",
    "    }\n",
    "\n",
    "# Automatically determine the number of workers based on CPU cores\n",
    "num_workers = int(multiprocessing.cpu_count() * 0.5)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor, tqdm(total=len(hres.prediction_timedelta.values) * len(hres.latitude.values) * len(hres.longitude.values)) as pbar:\n",
    "    futures = []\n",
    "    for lead_time in hres.prediction_timedelta.values:\n",
    "        for lat in hres.latitude.values:\n",
    "            for lon in hres.longitude.values:\n",
    "                future = executor.submit(process_location, lat, lon, lead_time)\n",
    "                futures.append(future)\n",
    "\n",
    "    # Wait for all futures to complete\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        result_list.append(future.result())\n",
    "        pbar.update(1)\n",
    "\n",
    "executor.shutdown(wait=True)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "result_df = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.sort_values(by=['lead_time', 'latitude', 'longitude']).reset_index(drop=True).to_pickle('EMOS/T2M/hres_2020_local.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [05:22<00:00,  7.87s/it]\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "def process_lead_time(lead_time):\n",
    "    hres_subset = hres.sel(prediction_timedelta=lead_time)\n",
    "\n",
    "    # Split hres data into training and test sets\n",
    "    hres_train = xr.concat([hres_subset.sel(time=slice(None, '2019-12-31')),\n",
    "                             hres_subset.sel(time=slice('2021-01-01', obs.time[-1] - pd.to_timedelta(lead_time)))], dim='time')\n",
    "    hres_test = hres_subset.sel(time=slice('2020-01-01', '2020-12-31'))\n",
    "\n",
    "    # Load ERA5 data\n",
    "    obs_train = obs.sel(time=hres_train.time + lead_time)\n",
    "    obs_test = obs.sel(time=hres_test.time + lead_time)\n",
    "\n",
    "    # Extract values from datasets\n",
    "    hres_train_values = hres_train.values\n",
    "    hres_test_values = hres_test.values\n",
    "    obs_train_values = obs_train.values\n",
    "    obs_test_values = obs_test.values\n",
    "\n",
    "    # Train EMOS model\n",
    "    emos_params = emos_est(ens_mean=hres_train_values, obs=obs_train_values, par_start=[0, 0, 0], forecast_global=hres_train)\n",
    "\n",
    "    # Calculate expected value of EMOS ensemble\n",
    "    emos_mu = emos_params.x[0] + emos_params.x[1] * hres_test_values\n",
    "\n",
    "    # Calculate CRPS, MAE, and MSE for EMOS using the expected value\n",
    "    crps_emos = emos_crps(params=emos_params.x, ens_mean=hres_test_values, obs=obs_test_values, forecast_global=hres_test)\n",
    "    mae_emos = np_spatial_avg(np.abs(emos_mu - obs_test_values).mean(axis=0),hres_test)\n",
    "    mse_emos = np_spatial_avg(((emos_mu - obs_test_values)**2).mean(axis=0),hres_test)\n",
    "\n",
    "    # Calculate MAE and MSE for deterministic forecast (replace this line with your deterministic forecast calculation)\n",
    "    mae_det = np_spatial_avg(np.abs(hres_test_values - obs_test_values).mean(axis=0),hres_test)\n",
    "    mse_det = np_spatial_avg(((hres_test_values - obs_test_values)**2).mean(axis=0), hres_test)\n",
    "\n",
    "    return {\n",
    "        'lead_time': lead_time,\n",
    "        'emos_params_x': emos_params.x.tolist(),\n",
    "        'crps_emos': crps_emos,\n",
    "        'mae_emos': mae_emos,\n",
    "        'mse_emos': mse_emos,\n",
    "        'mae_det': mae_det,\n",
    "        'mse_det': mse_det\n",
    "    }\n",
    "\n",
    "# Automatically determine the number of workers based on CPU cores\n",
    "num_workers = int(multiprocessing.cpu_count() * 0.5)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor, tqdm(total=len(hres.prediction_timedelta.values)) as pbar:\n",
    "    futures = []\n",
    "    for lead_time in hres.prediction_timedelta.values:\n",
    "        future = executor.submit(process_lead_time, lead_time)\n",
    "        futures.append(future)\n",
    "\n",
    "    # Wait for all futures to complete\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        result_list.append(future.result())\n",
    "        pbar.update(1)\n",
    "\n",
    "executor.shutdown(wait=True)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "result_df = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.sort_values(by='lead_time').reset_index(drop=True).to_pickle('EMOS/T2M/hres_2020_global.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IFS ENS done in 12.89 seconds\n",
      "Obs done in 2.31 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Load IFS ENS data\n",
    "ens = xr.open_zarr('gs://weatherbench2/datasets/ens/2018-2022-64x32_equiangular_conservative.zarr')['2m_temperature']\n",
    "#ens = ens.compute()\n",
    "ens_done_time = time.time() - start_time\n",
    "print('IFS ENS done in {:.2f} seconds'.format(ens_done_time))\n",
    "\n",
    "start_time = time.time()\n",
    "# Load Analysis data\n",
    "obs = xr.open_zarr('gs://weatherbench2/datasets/hres_t0/2016-2022-6h-64x32_equiangular_conservative.zarr')['2m_temperature'].sel(time=slice('2018-01-01', '2022-12-31'))\n",
    "obs = obs.compute()\n",
    "\n",
    "obs_done_time = time.time() - start_time\n",
    "print('Obs done in {:.2f} seconds'.format(obs_done_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = ens.drop_sel(time=pd.to_datetime('2019-10-17T00:00:00.000000000'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(102400)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens_train.isnull().sum().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1308)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens_train.isnull().sum(dim=[\"number\", \"latitude\", \"longitude\"]).argmax().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;2m_temperature&#x27; (number: 50, longitude: 64, latitude: 32)&gt;\n",
       "array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "...\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)\n",
       "Coordinates:\n",
       "  * latitude              (latitude) float64 -87.19 -81.56 ... 81.56 87.19\n",
       "  * longitude             (longitude) float64 0.0 5.625 11.25 ... 348.8 354.4\n",
       "  * number                (number) int32 1 2 3 4 5 6 7 ... 44 45 46 47 48 49 50\n",
       "    prediction_timedelta  timedelta64[ns] 06:00:00\n",
       "    time                  datetime64[ns] 2019-10-17\n",
       "Attributes:\n",
       "    long_name:      2 metre temperature\n",
       "    short_name:     t2m\n",
       "    standard_name:  unknown\n",
       "    units:          K</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'2m_temperature'</div><ul class='xr-dim-list'><li><span class='xr-has-index'>number</span>: 50</li><li><span class='xr-has-index'>longitude</span>: 64</li><li><span class='xr-has-index'>latitude</span>: 32</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-db625ec9-d4ff-452a-966b-61c5a9c1a189' class='xr-array-in' type='checkbox' checked><label for='section-db625ec9-d4ff-452a-966b-61c5a9c1a189' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>nan nan nan nan nan nan nan nan ... nan nan nan nan nan nan nan nan</span></div><div class='xr-array-data'><pre>array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "...\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)</pre></div></div></li><li class='xr-section-item'><input id='section-9130fee8-f1c8-4a0c-b712-2358e7cea844' class='xr-section-summary-in' type='checkbox'  checked><label for='section-9130fee8-f1c8-4a0c-b712-2358e7cea844' class='xr-section-summary' >Coordinates: <span>(5)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>latitude</span></div><div class='xr-var-dims'>(latitude)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-87.19 -81.56 ... 81.56 87.19</div><input id='attrs-18e611f0-54ab-416c-a756-b10a6619a46a' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-18e611f0-54ab-416c-a756-b10a6619a46a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ef2357d3-9aa1-4d25-846c-f8a09e9586d6' class='xr-var-data-in' type='checkbox'><label for='data-ef2357d3-9aa1-4d25-846c-f8a09e9586d6' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([-87.1875, -81.5625, -75.9375, -70.3125, -64.6875, -59.0625, -53.4375,\n",
       "       -47.8125, -42.1875, -36.5625, -30.9375, -25.3125, -19.6875, -14.0625,\n",
       "        -8.4375,  -2.8125,   2.8125,   8.4375,  14.0625,  19.6875,  25.3125,\n",
       "        30.9375,  36.5625,  42.1875,  47.8125,  53.4375,  59.0625,  64.6875,\n",
       "        70.3125,  75.9375,  81.5625,  87.1875])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>longitude</span></div><div class='xr-var-dims'>(longitude)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>0.0 5.625 11.25 ... 348.8 354.4</div><input id='attrs-6422412e-f7a1-420c-913b-b04a23e68cf2' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-6422412e-f7a1-420c-913b-b04a23e68cf2' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-13266786-f76e-4dc2-9f3e-e8fa0186118f' class='xr-var-data-in' type='checkbox'><label for='data-13266786-f76e-4dc2-9f3e-e8fa0186118f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([  0.   ,   5.625,  11.25 ,  16.875,  22.5  ,  28.125,  33.75 ,  39.375,\n",
       "        45.   ,  50.625,  56.25 ,  61.875,  67.5  ,  73.125,  78.75 ,  84.375,\n",
       "        90.   ,  95.625, 101.25 , 106.875, 112.5  , 118.125, 123.75 , 129.375,\n",
       "       135.   , 140.625, 146.25 , 151.875, 157.5  , 163.125, 168.75 , 174.375,\n",
       "       180.   , 185.625, 191.25 , 196.875, 202.5  , 208.125, 213.75 , 219.375,\n",
       "       225.   , 230.625, 236.25 , 241.875, 247.5  , 253.125, 258.75 , 264.375,\n",
       "       270.   , 275.625, 281.25 , 286.875, 292.5  , 298.125, 303.75 , 309.375,\n",
       "       315.   , 320.625, 326.25 , 331.875, 337.5  , 343.125, 348.75 , 354.375])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>number</span></div><div class='xr-var-dims'>(number)</div><div class='xr-var-dtype'>int32</div><div class='xr-var-preview xr-preview'>1 2 3 4 5 6 7 ... 45 46 47 48 49 50</div><input id='attrs-46c7d39d-50a1-46c3-8f98-7fb130813c1e' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-46c7d39d-50a1-46c3-8f98-7fb130813c1e' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e9d6ae6f-25e1-4c4f-a791-3e8f85bbc85a' class='xr-var-data-in' type='checkbox'><label for='data-e9d6ae6f-25e1-4c4f-a791-3e8f85bbc85a' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "       37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], dtype=int32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>prediction_timedelta</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>timedelta64[ns]</div><div class='xr-var-preview xr-preview'>06:00:00</div><input id='attrs-e620401d-fc49-4502-8e1d-aed45139014c' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-e620401d-fc49-4502-8e1d-aed45139014c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-9bf6e0ed-c164-4b9f-afe7-f0739e15b74b' class='xr-var-data-in' type='checkbox'><label for='data-9bf6e0ed-c164-4b9f-afe7-f0739e15b74b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>time since forecast_reference_time</dd><dt><span>standard_name :</span></dt><dd>forecast_period</dd></dl></div><div class='xr-var-data'><pre>array(21600000000000, dtype=&#x27;timedelta64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>time</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2019-10-17</div><input id='attrs-f22836a5-bfcf-407e-a153-01b57d7b19ff' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-f22836a5-bfcf-407e-a153-01b57d7b19ff' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-f3229059-8d08-4843-a812-3571fc354f1e' class='xr-var-data-in' type='checkbox'><label for='data-f3229059-8d08-4843-a812-3571fc354f1e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>initial time of forecast</dd><dt><span>standard_name :</span></dt><dd>forecast_reference_time</dd></dl></div><div class='xr-var-data'><pre>array(&#x27;2019-10-17T00:00:00.000000000&#x27;, dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-ea616664-1e6e-403c-9969-cf949d7bc71d' class='xr-section-summary-in' type='checkbox'  ><label for='section-ea616664-1e6e-403c-9969-cf949d7bc71d' class='xr-section-summary' >Indexes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>latitude</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-0e05e386-ac2a-4620-8461-471c28e3e345' class='xr-index-data-in' type='checkbox'/><label for='index-0e05e386-ac2a-4620-8461-471c28e3e345' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([ -87.18750000000003,  -81.56250000000001,            -75.9375,\n",
       "               -70.31249999999999,  -64.68750000000001,            -59.0625,\n",
       "                         -53.4375,            -47.8125,            -42.1875,\n",
       "                         -36.5625, -30.937499999999996, -25.312500000000004,\n",
       "              -19.687499999999996, -14.062499999999991,  -8.437499999999996,\n",
       "               -2.812500000000003,   2.812500000000003,   8.437500000000009,\n",
       "               14.062500000000004,  19.687499999999996,  25.312500000000004,\n",
       "                30.93750000000001,  36.562499999999986,             42.1875,\n",
       "                          47.8125,             53.4375,  59.062500000000014,\n",
       "                64.68750000000001,             70.3125,             75.9375,\n",
       "                81.56249999999997,   87.18750000000003],\n",
       "             dtype=&#x27;float64&#x27;, name=&#x27;latitude&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>longitude</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-da86401f-ab41-4adc-966f-971febbb9b4e' class='xr-index-data-in' type='checkbox'/><label for='index-da86401f-ab41-4adc-966f-971febbb9b4e' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([               0.0,              5.625,              11.25,\n",
       "                          16.875,               22.5,             28.125,\n",
       "                           33.75,             39.375,               45.0,\n",
       "                          50.625,              56.25,  61.87499999999999,\n",
       "                            67.5,             73.125,              78.75,\n",
       "                          84.375,               90.0,             95.625,\n",
       "                          101.25,            106.875,              112.5,\n",
       "                         118.125, 123.74999999999999,            129.375,\n",
       "                           135.0,            140.625,             146.25,\n",
       "                         151.875,              157.5,            163.125,\n",
       "                          168.75,            174.375,              180.0,\n",
       "                         185.625,             191.25,            196.875,\n",
       "                           202.5,            208.125,             213.75,\n",
       "                         219.375,              225.0, 230.62499999999997,\n",
       "                          236.25,            241.875, 247.49999999999997,\n",
       "                         253.125,             258.75,            264.375,\n",
       "                           270.0,            275.625,             281.25,\n",
       "                         286.875,              292.5,            298.125,\n",
       "                          303.75,            309.375,              315.0,\n",
       "                         320.625,             326.25,            331.875,\n",
       "                           337.5,            343.125,             348.75,\n",
       "                         354.375],\n",
       "             dtype=&#x27;float64&#x27;, name=&#x27;longitude&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>number</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-9014a499-43d0-4da0-946b-359178ba0a55' class='xr-index-data-in' type='checkbox'/><label for='index-9014a499-43d0-4da0-946b-359178ba0a55' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Int64Index([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "            18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "            35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50],\n",
       "           dtype=&#x27;int64&#x27;, name=&#x27;number&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-623630df-4120-4739-ba08-b0a958457ce0' class='xr-section-summary-in' type='checkbox'  checked><label for='section-623630df-4120-4739-ba08-b0a958457ce0' class='xr-section-summary' >Attributes: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>2 metre temperature</dd><dt><span>short_name :</span></dt><dd>t2m</dd><dt><span>standard_name :</span></dt><dd>unknown</dd><dt><span>units :</span></dt><dd>K</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray '2m_temperature' (number: 50, longitude: 64, latitude: 32)>\n",
       "array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "...\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)\n",
       "Coordinates:\n",
       "  * latitude              (latitude) float64 -87.19 -81.56 ... 81.56 87.19\n",
       "  * longitude             (longitude) float64 0.0 5.625 11.25 ... 348.8 354.4\n",
       "  * number                (number) int32 1 2 3 4 5 6 7 ... 44 45 46 47 48 49 50\n",
       "    prediction_timedelta  timedelta64[ns] 06:00:00\n",
       "    time                  datetime64[ns] 2019-10-17\n",
       "Attributes:\n",
       "    long_name:      2 metre temperature\n",
       "    short_name:     t2m\n",
       "    standard_name:  unknown\n",
       "    units:          K"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens_train.isel(time=1308)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 50, 64, 32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102400"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50*64*32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|██▏                                                                                                                                                                | 1656/124928 [01:57<2:14:40, 15.25it/s]/home/tbiegert/.conda/envs/wb2/lib/python3.9/site-packages/properscoring/_crps.py:16: RuntimeWarning: overflow encountered in multiply\n",
      "  return _normconst * np.exp(-(x * x) / 2.0)\n",
      "/home/tbiegert/.conda/envs/wb2/lib/python3.9/site-packages/properscoring/_crps.py:16: RuntimeWarning: overflow encountered in multiply\n",
      "  return _normconst * np.exp(-(x * x) / 2.0)\n",
      "/home/tbiegert/.conda/envs/wb2/lib/python3.9/site-packages/properscoring/_crps.py:16: RuntimeWarning: overflow encountered in multiply\n",
      "  return _normconst * np.exp(-(x * x) / 2.0)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 124928/124928 [2:37:02<00:00, 13.26it/s]\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "with tqdm(total=len(ens.prediction_timedelta.values) * len(ens.latitude.values) * len(ens.longitude.values)) as pbar:\n",
    "    for lead_time in ens.prediction_timedelta.values:\n",
    "        ens_sub = ens.sel(prediction_timedelta=lead_time)\n",
    "        ens_sub = ens_sub.compute()\n",
    "        for lat in ens.latitude.values:\n",
    "            for lon in ens.longitude.values:\n",
    "\n",
    "                ens_subset = ens_sub.sel(latitude=lat, longitude=lon)\n",
    "\n",
    "                # Split ens data into training and test sets\n",
    "                ens_train = xr.concat([ens_subset.sel(time=slice(None, '2019-12-31')),\n",
    "                                         ens_subset.sel(time=slice('2021-01-01', obs.time[-2] - pd.to_timedelta(lead_time)))], dim='time')\n",
    "                ens_test = ens_subset.sel(time=slice('2020-01-01', '2020-12-31'))\n",
    "\n",
    "                # Load ERA5 data\n",
    "                obs_train = obs.sel(latitude=lat, longitude=lon, time=ens_train.time + lead_time)\n",
    "                obs_test = obs.sel(latitude=lat, longitude=lon, time=ens_test.time + lead_time)\n",
    "\n",
    "                # Extract values from datasets\n",
    "                ens_train_values = ens_train.values\n",
    "                ens_test_values = ens_test.values\n",
    "                obs_train_values = obs_train.values\n",
    "                obs_test_values = obs_test.values\n",
    "\n",
    "                # Train EMOS model\n",
    "                emos_params = emos_est(ens_mean=ens_train_values.mean(axis=1), obs=obs_train_values, par_start=[0, 0, 0, 0], ens_sd=ens_train_values.std(axis=1))\n",
    "\n",
    "                # Calculate expected value of EMOS ensemble\n",
    "                ens_test_values_mean = ens_test_values.mean(axis=1)\n",
    "                emos_mu = emos_params.x[0] + emos_params.x[1] * ens_test_values_mean\n",
    "\n",
    "                # Calculate CRPS, MAE, and MSE for EMOS using the expected value\n",
    "                crps_emos = emos_crps(params=emos_params.x, ens_mean=ens_test_values_mean, obs=obs_test_values, ens_sd=ens_test_values.std(axis=1))\n",
    "                mae_emos = np.mean(np.abs(emos_mu - obs_test_values))\n",
    "                mse_emos = np.mean((emos_mu - obs_test_values)**2)\n",
    "\n",
    "                # Calculate MAE and MSE for deterministic forecast (replace this line with your deterministic forecast calculation)\n",
    "                ens_mean_mae = np.mean(np.abs(ens_test_values_mean - obs_test_values))\n",
    "                ens_mean_mse = np.mean((ens_test_values_mean - obs_test_values)**2)\n",
    "\n",
    "                # Append results to the list\n",
    "                result_list.append({\n",
    "                    'latitude': lat,\n",
    "                    'longitude': lon,\n",
    "                    'lead_time': lead_time,\n",
    "                    'emos_params_x': emos_params.x.tolist(),\n",
    "                    'crps_emos': crps_emos,\n",
    "                    'mae_emos': mae_emos,\n",
    "                    'mse_emos': mse_emos,\n",
    "                    'ens_mean_mae': ens_mean_mae,\n",
    "                    'ens_mean_mse': ens_mean_mse\n",
    "                })\n",
    "                \n",
    "                pbar.update(1)\n",
    "    \n",
    "# Convert the list of dictionaries to a DataFrame and save it for each iteration\n",
    "result_df = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_pickle('EMOS/T2M/ens_2020_local.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lead times: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 61/61 [1:07:23<00:00, 66.29s/it]\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "for lead_time in tqdm(ens.prediction_timedelta.values, desc=\"Processing lead times\"):\n",
    "    \n",
    "    ens_subset = ens.sel(prediction_timedelta=lead_time)\n",
    "    ens_subset = ens_subset.compute()\n",
    "\n",
    "    # Split ens data into training and test sets\n",
    "    ens_train = xr.concat([ens_subset.sel(time=slice(None, '2019-12-31')),\n",
    "                             ens_subset.sel(time=slice('2021-01-01', obs.time[-2] - pd.to_timedelta(lead_time)))], dim='time')\n",
    "    ens_test = ens_subset.sel(time=slice('2020-01-01', '2020-12-31'))\n",
    "\n",
    "    # Load ERA5 data\n",
    "    obs_train = obs.sel(time=ens_train.time + lead_time)\n",
    "    obs_test = obs.sel(time=ens_test.time + lead_time)\n",
    "\n",
    "    # Extract values from datasets\n",
    "    ens_train_values = ens_train.values\n",
    "    ens_test_values = ens_test.values\n",
    "    obs_train_values = obs_train.values\n",
    "    obs_test_values = obs_test.values\n",
    "\n",
    "    # Train EMOS model \n",
    "    emos_params = emos_est(ens_mean=ens_train_values.mean(axis=1), obs=obs_train_values, par_start=[0, 0, 0, 0], ens_sd=ens_train_values.std(axis=1), forecast_global=ens_train)\n",
    "\n",
    "    # Calculate expected value of EMOS ensemble\n",
    "    ens_test_values_mean = ens_test_values.mean(axis=1)\n",
    "    emos_mu = emos_params.x[0] + emos_params.x[1] * ens_test_values_mean\n",
    "\n",
    "    # Calculate CRPS, MAE, and MSE for EMOS using the expected value\n",
    "    crps_emos = emos_crps(params=emos_params.x, ens_mean=ens_test_values_mean, obs=obs_test_values, ens_sd=ens_test_values.std(axis=1), forecast_global=ens_test)\n",
    "    mae_emos = np_spatial_avg(np.abs(emos_mu - obs_test_values).mean(axis=0),ens_test)\n",
    "    mse_emos = np_spatial_avg(((emos_mu - obs_test_values)**2).mean(axis=0),ens_test)\n",
    "\n",
    "    # Calculate MAE and MSE for deterministic forecast (replace this line with your deterministic forecast calculation)\n",
    "    ens_mean_mae = np_spatial_avg(np.abs(ens_test_values_mean - obs_test_values).mean(axis=0),ens_test)\n",
    "    ens_mean_mse = np_spatial_avg(((ens_test_values_mean - obs_test_values)**2).mean(axis=0), ens_test)\n",
    "\n",
    "    # Append results to the list\n",
    "    result_list.append({\n",
    "        'lead_time': lead_time,\n",
    "        'emos_params_x': emos_params.x.tolist(),\n",
    "        'crps_emos': crps_emos,\n",
    "        'mae_emos': mae_emos,\n",
    "        'mse_emos': mse_emos,\n",
    "        'ens_mean_mae': ens_mean_mae,\n",
    "        'ens_mean_mse': ens_mean_mse\n",
    "    })\n",
    "    \n",
    "# Convert the list of dictionaries to a DataFrame and save it for each iteration\n",
    "result_df = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_pickle('EMOS/T2M/ens_2020_global.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
